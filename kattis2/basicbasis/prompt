You are given a sequence of n bit strings b_1, b_2, ldots , b_ n, each with k times 4 bits. You are also given another sequence of m bit strings a_1, a_2, ldots , a_ m, each also with k times 4 bits. Let f(x) denote the minimum index i such that it is possible to take a non-empty subset of b_1, b_2, ldots , b_ i, XOR them all together, and get x. If there is no such index, f(x) = -1. Print the values f(a_1), f(a_2), ldots , f(a_ m). Input The first line of input contains three integers n (1 le n le 1, 000), m (1 le m le 1, 000) and k (1 le k le 40), where n is the length of sequence b, m is the length of sequence a, and the elements of both sequences are bit strings with k times 4 bits. Each of the next n lines contains a hexadecimal representation of b_ i as a string of length k. The strings consist only of hexadecimal digits (‘0’–‘9’ and ‘a’–‘f’). Then, each of the next m lines contains a hexadecimal representation of a_ i in the same format as above. Output Output m lines with a single integer on each line, where the integer on the ith line is f(a_ i). Sample Input 1 Sample Output 1 3 5 2 02 e1 fa 02 e3 1b e1 ff 1 2 3 2 -1 Sample Input 2 Sample Output 2 5 6 2 01 02 04 08 10 01 02 03 04 05 64 1 2 2 3 3 -1